{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Amazon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] sframe.cython.cy_server: SFrame v2.1 started. Logging /tmp/sframe_server_1518774093.log\n"
     ]
    }
   ],
   "source": [
    "products = sframe.SFrame('amazon_baby.gl/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform test cleaning\n",
    "* Remove punctuation (simple text cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None, string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['review clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Fill 'n/a' reviews with empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products.fillna('review','')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract sentiments\n",
    "Ignore all ratings = 3, since they don't tell us anything useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = products[products['rating'] != 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column in products called `sentiment` where we assign positive sentiment to review if rating > 3 and -1 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3\n",
    "                                                else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data = products.random_split(.8, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the word count vector for each review\n",
    "\n",
    "We will now compute the word count for each word that appears in the reviews. A vector consisting of word counts is often referred to as **bag-of-word features**. Since most words occur in only a few reviews, word count vectors are sparse. For this reason, scikit-learn and many other tools use sparse matrices to store a collection of word count vectors. Refer to appropriate manuals to produce sparse word count vectors. General steps for extracting word count vectors are as follows:\n",
    "\n",
    "* Learn a vocabulary (set of all words) from the training data. Only the words that show up in the training data will be considered for feature extraction.\n",
    "* Compute the occurrences of the words in each review and collect them into a row vector.\n",
    "* Build a sparse matrix where each row is the word count vector for the corresponding review. Call this matrix **train_matrix**.\n",
    "* Using the same mapping between words and columns, convert the test data into a sparse matrix **test_matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "train_matrix = vectorizer.fit_transform(train_data['review clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_matrix = vectorizer.transform(test_data['review clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data.\n",
    "\n",
    "7. Learn a logistic regression classifier using the training data. If you are using scikit-learn, you should create an instance of the LogisticRegression class and then call the method fit() to train the classifier. This model should use the sparse word count matrix (train_matrix) as features and the column sentiment of train_data as the target. Use the default values for other parameters. Call this model sentiment_model.\n",
    "\n",
    "8. There should be over 100,000 coefficients in this sentiment_model. Recall from the lecture that positive weights w_j correspond to weights that cause positive sentiment, while negative weights correspond to negative sentiment. Calculate the number of positive (>= 0, which is actually nonnegative) coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "sentiment_model = logistic.fit(train_matrix, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question: How many weights are >= 0?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121712"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentiment_model.coef_.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positive = [p for p in list(sentiment_model.coef_.flatten()) if p >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87151"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with logistic regression\n",
    "\n",
    "9. Now that a model is trained, we can make predictions on the test data. In this section, we will explore this in the context of 3 data points in the test data. Take the 11th, 12th, and 13th data points in the test data and save them to sample_test_data. The following cell extracts the three data points from the SFrame test_data and print their content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-------------------------------+--------+\n",
      "|              name             |             review            | rating |\n",
      "+-------------------------------+-------------------------------+--------+\n",
      "|   Our Baby Girl Memory Book   | Absolutely love it and all... |  5.0   |\n",
      "| Wall Decor Removable Decal... | Would not purchase again o... |  2.0   |\n",
      "| New Style Trailing Cherry ... | Was so excited to get this... |  1.0   |\n",
      "+-------------------------------+-------------------------------+--------+\n",
      "+-------------------------------+-----------+\n",
      "|          review clean         | sentiment |\n",
      "+-------------------------------+-----------+\n",
      "| Absolutely love it and all... |     1     |\n",
      "| Would not purchase again o... |     -1    |\n",
      "| Was so excited to get this... |     -1    |\n",
      "+-------------------------------+-----------+\n",
      "[3 rows x 5 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_test_data = test_data[10:13]\n",
    "print(sample_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absolutely love it and all of the Scripture in it.  I purchased the Baby Boy version for my grandson when he was born and my daughter-in-law was thrilled to receive the same book again.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data[0]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Would not purchase again or recommend. The decals were thick almost plastic like and were coming off the wall as I was applying them! The would NOT stick! Literally stayed stuck for about 5 minutes then started peeling off.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data[1]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Was so excited to get this product for my baby girls bedroom!  When I got it the back is NOT STICKY at all!  Every time I walked into the bedroom I was picking up pieces off of the floor!  Very very frustrating!  Ended up having to super glue it to the wall...very disappointing.  I wouldn't waste the time or money on it.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data[2]['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make a class prediction for the sample_test_data. The sentiment_model should predict +1 if the sentiment is positive and -1 if the sentiment is negative. Recall from the lecture that the score (sometimes called margin) for the logistic regression model is defined as:\n",
    "\n",
    "score$_i$=$\\mathbf{w}^⊺h(\\mathbf{x}_i)$\n",
    "\n",
    "where $h(\\mathbf{x}_i)$ represents the features for data point $i$. We will write some code to obtain the scores. For each row, the score (or margin) is a number in the range (-inf, inf). Use a pre-built function in your tool to calculate the score of each data point in sample_test_data. In scikit-learn, you can call the `decision_function()` function.\n",
    "\n",
    "Hint: You'd probably need to convert sample_test_data into the sparse matrix format first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_test_matrix = vectorizer.transform(sample_test_data['review clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  5.60193782  -3.1693431  -10.42378132]\n"
     ]
    }
   ],
   "source": [
    "scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediciting Sentiment\n",
    "\n",
    "11. These scores can be used to make class predictions as follows:\n",
    "\n",
    "$\\hat{\\mathbf{y}}_i=\\{\\begin{array}+1\\,\\,\\,if\\, \\mathbf{w}^Th(\\mathbf{x}_i)>0 \\\\\n",
    "                  −1\\,\\,\\,if\\, \\mathbf{w}^Th(\\mathbf{x}_i) \\le 0 \\end{array} $\n",
    "\n",
    "Using scores, write code to calculate predicted labels for sample_test_data.\n",
    "\n",
    "**Checkpoint**: Make sure your class predictions match with the ones obtained from sentiment_model. The logistic regression classifier in scikit-learn comes with the predict function for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment = sentiment_model.predict(sample_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.67713366e-03,   9.96322866e-01],\n",
       "       [  9.59664165e-01,   4.03358355e-02],\n",
       "       [  9.99970284e-01,   2.97164132e-05]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.predict_proba(sample_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model.predict(sample_test_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Predictions\n",
    "\n",
    "Recall from the lectures that we can also calculate the probability predictions from the scores using:\n",
    "\n",
    "$$P(\\mathbf{y}_i = +1|\\mathbf{x}_i,\\mathbf{w})=\\frac{1}{1+\\exp(−\\mathbf{w}^⊺h(\\mathbf{x}_i))}$$\n",
    "\n",
    "Using the scores calculated previously, write code to calculate the probability that a sentiment is positive using the above formula. For each row, the probabilities should be a number in the range [0, 1].\n",
    "\n",
    "Checkpoint: Make sure your probability predictions match the ones obtained from sentiment_model.\n",
    "\n",
    "**Quiz question**: Of the three data points in sample_test_data, which one (first, second, or third) has the lowest probability of being classified as a positive review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_prob(scores):\n",
    "    return 1/(1 + np.exp(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.96322866e-01,   4.03358355e-02,   2.97164132e-05])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_prob(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most positive (and negative) review\n",
    "\n",
    "We now turn to examining the full test dataset, **test_data**, and use `sklearn.linear_model.LogisticRegression` to form predictions on all of the test data points.\n",
    "\n",
    "Using the sentiment_model, find the 20 reviews in the entire test_data with the highest probability of being classified as a positive review. We refer to these as the \"most positive reviews.\"\n",
    "\n",
    "To calculate these top-20 reviews, use the following steps:\n",
    "\n",
    "1. Make probability predictions on test_data using the sentiment_model.\n",
    "2. Sort the data according to those predictions and pick the top 20.\n",
    "\n",
    "**Quiz Question**: Which of the following products are represented in the 20 most positive reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proba = sentiment_model.predict_proba(test_matrix)\n",
    "sentiment = sentiment_model.predict(test_matrix)\n",
    "test_data['predicted_sentiment'] = sentiment\n",
    "test_data['predicted_proba'] = proba[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_twenty = test_data.sort('predicted_proba', ascending=False)[:20][['name', 'sentiment', 'predicted_sentiment', 'predicted_proba']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-----------+---------------------+-----------------+\n",
      "|              name             | sentiment | predicted_sentiment | predicted_proba |\n",
      "+-------------------------------+-----------+---------------------+-----------------+\n",
      "| Baby Jogger City Mini GT S... |     1     |          1          |       1.0       |\n",
      "| Graco FastAction Fold Jogg... |     1     |          1          |       1.0       |\n",
      "| Evenflo 6 Pack Classic Gla... |     1     |          1          |       1.0       |\n",
      "| Britax Decathlon Convertib... |     1     |          1          |       1.0       |\n",
      "| Diono RadianRXT Convertibl... |     1     |          1          |       1.0       |\n",
      "| P'Kolino Silly Soft Seatin... |     1     |          1          |       1.0       |\n",
      "| Mamas &amp; Papas 2014 Urb... |     1     |          1          |       1.0       |\n",
      "| Simple Wishes Hands-Free B... |     1     |          1          |       1.0       |\n",
      "| Roan Rocco Classic Pram St... |     1     |          1          |       1.0       |\n",
      "| Freemie Hands-Free Conceal... |     1     |          1          |       1.0       |\n",
      "| Fisher-Price Cradle 'N Swi... |     1     |          1          |       1.0       |\n",
      "| Britax 2012 B-Agile Stroll... |     1     |          1          |       1.0       |\n",
      "| Evenflo X Sport Plus Conve... |     1     |          1          |       1.0       |\n",
      "| Graco Pack 'n Play Element... |     1     |          1          |       1.0       |\n",
      "| Baby Einstein Around The W... |     1     |          1          |       1.0       |\n",
      "| Buttons Cloth Diaper Cover... |     1     |          1          |       1.0       |\n",
      "| Infantino Wrap and Tie Bab... |     1     |          1          |       1.0       |\n",
      "| Ikea 36 Pcs Kalas Kids Pla... |     1     |          1          |       1.0       |\n",
      "| Summer Infant Wide View Di... |     1     |          1          |       1.0       |\n",
      "| Baby Jogger City Mini GT D... |     1     |          1          |       1.0       |\n",
      "+-------------------------------+-----------+---------------------+-----------------+\n",
      "[20 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_twenty.print_rows(num_rows=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us repeat this exercise to find the \"most negative reviews.\" Use the prediction probabilities to find the 20 reviews in the test_data with the lowest probability of being classified as a positive review. Repeat the same steps above but make sure you sort in the opposite order.\n",
    "\n",
    "**Quiz Question**: Which of the following products are represented in the 20 most negative reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottom_twenty = test_data.sort('predicted_proba')[:20][['name', 'sentiment', 'predicted_sentiment', 'predicted_proba']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-----------+---------------------+\n",
      "|              name             | sentiment | predicted_sentiment |\n",
      "+-------------------------------+-----------+---------------------+\n",
      "| Fisher-Price Ocean Wonders... |     -1    |          -1         |\n",
      "| Levana Safe N'See Digital ... |     -1    |          -1         |\n",
      "| Safety 1st Exchangeable Ti... |     -1    |          -1         |\n",
      "| Adiri BPA Free Natural Nur... |     -1    |          -1         |\n",
      "| VTech Communications Safe ... |     -1    |          -1         |\n",
      "| The First Years True Choic... |     -1    |          -1         |\n",
      "| Safety 1st High-Def Digita... |     -1    |          -1         |\n",
      "| Cloth Diaper Sprayer--styl... |     -1    |          -1         |\n",
      "| Philips AVENT Newborn Star... |     -1    |          -1         |\n",
      "| Motorola Digital Video Bab... |     -1    |          -1         |\n",
      "| Ellaroo Mei Tai Baby Carri... |     -1    |          -1         |\n",
      "| Cosco Alpha Omega Elite Co... |     -1    |          -1         |\n",
      "| Chicco Cortina KeyFit 30 T... |     -1    |          -1         |\n",
      "| Belkin WeMo Wi-Fi Baby Mon... |     -1    |          -1         |\n",
      "| Peg-Perego Tatamia High Ch... |     -1    |          -1         |\n",
      "| NUK Cook-n-Blend Baby Food... |     -1    |          -1         |\n",
      "| VTech Communications Safe ... |     -1    |          -1         |\n",
      "| Safety 1st Deluxe 4-in-1 B... |     -1    |          -1         |\n",
      "| Regalo My Cot Portable Bed... |     -1    |          -1         |\n",
      "| Thirsties Hemp Inserts 2 P... |     1     |          -1         |\n",
      "+-------------------------------+-----------+---------------------+\n",
      "+-------------------+\n",
      "|  predicted_proba  |\n",
      "+-------------------+\n",
      "|  8.461184914e-16  |\n",
      "| 1.60330303532e-15 |\n",
      "| 8.10907967539e-14 |\n",
      "|  9.8583251164e-14 |\n",
      "| 1.91524573043e-13 |\n",
      "| 3.35646766724e-13 |\n",
      "| 3.27905991032e-11 |\n",
      "| 3.33371658152e-11 |\n",
      "| 9.47773745898e-11 |\n",
      "| 9.62891204048e-11 |\n",
      "| 4.34952889745e-10 |\n",
      "| 4.37998381729e-10 |\n",
      "| 5.57542034396e-10 |\n",
      "| 5.70673312631e-10 |\n",
      "| 5.78760331118e-10 |\n",
      "|  6.1912828267e-10 |\n",
      "|  8.0406414479e-10 |\n",
      "| 1.07704704618e-09 |\n",
      "| 1.59653627349e-09 |\n",
      "| 1.65240524532e-09 |\n",
      "+-------------------+\n",
      "[20 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bottom_twenty.print_rows(num_rows=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz answers\n",
    "1. 85974\n",
    "2. third\n",
    "3. top_twenty.print_rows(num_rows=20)\n",
    "4. bottom_twenty.print_rows(num_rows=20)\n",
    "5. 0.93\n",
    "6. No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9322954163666907"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct = len(test_data[test_data['sentiment'] == test_data['predicted_sentiment']])\n",
    "total = len(test_data)\n",
    "accuracy = correct / float(total)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn another classifier with fewer words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_data['review clean'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_data['review clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "simple_model = logistic.fit(train_matrix_word_subset, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_model_coef_table = sframe.SFrame({'word':significant_words,\n",
    "                                         'coefficient':simple_model.coef_.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_positive_words = simple_model_coef_table[simple_model_coef_table['coefficient'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model_coef_table = sframe.SFrame({'word':vectorizer.vocabulary_,\n",
    "                                         'coefficient':sentiment_model.coef_.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_subset = sentiment_model_coef_table[sentiment_model_coef_table['word'].is_in(significant_words)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, not all positive words in the simple model are positive in the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simple_model_predict = simple_model.predict(train_matrix_word_subset)\n",
    "train_data['predicted_simple_model'] = simple_model_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_predict = sentiment_model.predict(train_matrix)\n",
    "train_data['predicted_full_model'] = full_model_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.866822570007 0.96849703184\n"
     ]
    }
   ],
   "source": [
    "simple_model_train_accuracy = len(train_data[train_data['sentiment'] == train_data['predicted_simple_model']])/float(len(train_data))\n",
    "full_model_train_accuracy = len(train_data[train_data['sentiment'] == train_data['predicted_full_model']])/float(len(train_data))\n",
    "print(simple_model_train_accuracy, full_model_train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_model_test_predict = simple_model.predict(test_matrix_word_subset)\n",
    "test_data['predicted_simple_model'] = simple_model_test_predict\n",
    "full_model_test_predict = sentiment_model.predict(test_matrix)\n",
    "test_data['predicted_full_model'] = full_model_test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.869360451164 0.932295416367\n"
     ]
    }
   ],
   "source": [
    "simple_model_test_accuracy = len(test_data[test_data['sentiment'] == test_data['predicted_simple_model']])/float(len(test_data))\n",
    "full_model_test_accuracy = len(test_data[test_data['sentiment'] == test_data['predicted_full_model']])/float(len(test_data))\n",
    "print(simple_model_test_accuracy, full_model_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_model = dummy.fit(train_matrix, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data['dummy'] = dummy_model.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.842782577394\n"
     ]
    }
   ],
   "source": [
    "dummy_test_accuracy = len(test_data[test_data['sentiment'] == test_data['dummy']])/float(len(test_data))\n",
    "print(dummy_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
